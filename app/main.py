# Complete FastAPI endpoints - Replace the relevant parts in your main.py
from fastapi import FastAPI, Depends, HTTPException, Request
from sqlalchemy.orm import Session
from sqlalchemy import text
from pydantic import BaseModel
from app.db import get_db, insert_product, insert_products_bulk
from app.qdrant_utils import search_documents, insert_documents, create_collection, delete_document
from app.llm_utils import (
    call_deepseek,
    store_conversation,
    get_conversation_history,
    get_all_products_from_supabase,
    enhanced_product_search,
    add_single_product_with_embedding,
    advanced_text_normalization,
    create_comprehensive_product_text,
    EMBEDDING_DIMENSION,
    embedding_model,
    sync_products_to_qdrant,
)
from fastapi import File, UploadFile
import tempfile
import os
from typing import List, Optional
from PyPDF2 import PdfReader
import docx
import logging
import sys
import json
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from supabase_auth import user_router
from fastapi.middleware.cors import CORSMiddleware
import re
from uuid import uuid4
# Initialize FastAPI app
app = FastAPI()
app.include_router(user_router)
# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "https://your-production-domain.com"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
# This CORS config applies to all endpoints, including /user/info
# Pydantic models
class ChatRequest(BaseModel):
    question: str
class ProductCreate(BaseModel):
    id: str = None  # allow explicit id if needed
    name: str
    in_stock: bool
    quantity: int
    image_url: str
    category: str = ""
    description: str = ""
class BulkProductCreate(BaseModel):
    products: List[ProductCreate]
class DocumentInsertRequest(BaseModel):
    document: str
    id: Optional[str] = None  # Use string id
class ProductUpdate(BaseModel):
    name: Optional[str] = None
    in_stock: Optional[bool] = None
    quantity: Optional[int] = None
    image_url: Optional[str] = None
    category: Optional[str] = None
    description: Optional[str] = None
def get_user_id_from_request(request: Request):
    """Extract user ID from request session."""
    session_token = request.cookies.get("session_token")
    if not session_token:
        return None
    try:
        from supabase import create_client
        SUPABASE_URL = os.getenv("SUPABASE_URL")
        SUPABASE_KEY = os.getenv("SUPABASE_KEY")
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        user_resp = supabase.auth.get_user(session_token)
        if hasattr(user_resp, "user") and user_resp.user:
            user = user_resp.user
        elif isinstance(user_resp, dict) and "user" in user_resp:
            user = user_resp["user"]
        if user and hasattr(user, "id"):
            return user.id
        elif user and "id" in user:
            return user["id"]
    except Exception as e:
        logging.error(f"Error getting user id from session: {e}")
    return None
def get_current_user_id(request: Request) -> str:
    return get_user_id_from_request(request)
@app.get("/")
def read_root():
    return {"message": "Enhanced Customer Support System is running!"}
# --- NEW: Arabic normalization and synonym matching ---
def normalize_arabic(text):
    # Basic normalization: remove diacritics, unify forms, lowercase, remove punctuation
    if not text:
        return ""
    text = text.lower()
    text = re.sub(r'[Ù‹ÙŒÙÙÙÙÙ‘Ù’Ù€]', '', text)  # Remove Arabic diacritics
    text = text.replace('Ø£', 'Ø§').replace('Ø¥', 'Ø§').replace('Ø¢', 'Ø§')
    text = text.replace('Ø©', 'Ù‡')
    text = text.replace('Ù‰', 'ÙŠ')
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    text = text.strip()
    return text
def get_arabic_synonyms():
    # Expand this dictionary as needed for more robust matching
    return {
        "Ø³Ù…Ø§Ø¹Ø§Øª ÙˆØ§ÙŠØ±Ù„Ø³": ["wireless headphones", "Ø³Ù…Ø§Ø¹Ø© ÙˆØ§ÙŠØ±Ù„Ø³", "Ø³Ù…Ø§Ø¹Ø§Øª Ù„Ø§Ø³Ù„ÙƒÙŠØ©", "Ø³Ù…Ø§Ø¹Ø© Ù„Ø§Ø³Ù„ÙƒÙŠØ©"],
        "Ø³Ù…Ø§Ø¹Ø© ÙˆØ§ÙŠØ±Ù„Ø³": ["wireless headphones", "Ø³Ù…Ø§Ø¹Ø§Øª ÙˆØ§ÙŠØ±Ù„Ø³", "Ø³Ù…Ø§Ø¹Ø§Øª Ù„Ø§Ø³Ù„ÙƒÙŠØ©", "Ø³Ù…Ø§Ø¹Ø© Ù„Ø§Ø³Ù„ÙƒÙŠØ©"],
        "Ø³Ù…Ø§Ø¹Ø§Øª Ù„Ø§Ø³Ù„ÙƒÙŠØ©": ["wireless headphones", "Ø³Ù…Ø§Ø¹Ø§Øª ÙˆØ§ÙŠØ±Ù„Ø³", "Ø³Ù…Ø§Ø¹Ø© ÙˆØ§ÙŠØ±Ù„Ø³", "Ø³Ù…Ø§Ø¹Ø© Ù„Ø§Ø³Ù„ÙƒÙŠØ©"],
        "Ø³Ù…Ø§Ø¹Ø© Ù„Ø§Ø³Ù„ÙƒÙŠØ©": ["wireless headphones", "Ø³Ù…Ø§Ø¹Ø§Øª ÙˆØ§ÙŠØ±Ù„Ø³", "Ø³Ù…Ø§Ø¹Ø© ÙˆØ§ÙŠØ±Ù„Ø³", "Ø³Ù…Ø§Ø¹Ø§Øª Ù„Ø§Ø³Ù„ÙƒÙŠØ©"],
        # Add more as needed
    }
def query_matches_product(query, product):
    # Normalize query and product name/description
    norm_query = normalize_arabic(query)
    norm_name = normalize_arabic(product.get("name", ""))
    norm_desc = normalize_arabic(product.get("description", ""))
    # Direct match
    if norm_query in norm_name or norm_query in norm_desc:
        return True
    # Synonym match
    synonyms = get_arabic_synonyms()
    for key, syns in synonyms.items():
        if norm_query == normalize_arabic(key) or norm_query in [normalize_arabic(s) for s in syns]:
            for s in [key] + syns:
                if normalize_arabic(s) in norm_name or normalize_arabic(s) in norm_desc:
                    return True
    return False
# --- Conversation Embedding Collection Name ---
CONV_COLLECTION = "conversation_memory"

# --- Store Conversation with Embedding ---
def store_conversation_with_embedding(user_id, user_message, llm_response, db=None):
    """
    Store conversation turn in DB and Qdrant with embedding.
    """
    import datetime
    from app.qdrant_utils import insert_documents, create_collection

    conv_id = str(uuid4())
    created_at = datetime.datetime.utcnow()
    # Store in DB
    if db:
        db.execute(
            text(
                "INSERT INTO conversations (id, user_id, user_message, llm_message, created_at) VALUES (:id, :user_id, :user_message, :llm_message, :created_at)"
            ),
            {
                "id": conv_id,
                "user_id": user_id,
                "user_message": user_message,
                "llm_message": llm_response,
                "created_at": created_at,
            },
        )
        db.commit()
    # Store embedding in Qdrant
    try:
        # Create collection if not exists
        try:
            create_collection(CONV_COLLECTION, EMBEDDING_DIMENSION)
        except Exception:
            pass
        # Use user_message + llm_response as the text for embedding
        text_for_embedding = f"USER: {user_message}\nASSISTANT: {llm_response}"
        embedding = embedding_model.encode([text_for_embedding])
        payload = {
            "user_id": user_id,
            "user_message": user_message,
            "llm_message": llm_response,
            "created_at": str(created_at),
            "conversation_id": conv_id,
        }
        insert_documents(
            [text_for_embedding],
            [conv_id],
            collection_name=CONV_COLLECTION,
            embeddings=embedding,
            payloads=[payload],
        )
    except Exception as e:
        logging.error(f"Failed to store conversation embedding: {e}")
    return conv_id

# --- List Conversations for Sidebar ---
@app.get("/user/conversations/")
async def list_user_conversations(
    request: Request,
    user_id: str = Depends(get_current_user_id),
    db: Session = Depends(get_db),
    limit: int = 20,
):
    """
    List all conversations for the current user (for sidebar/history).
    """
    try:
        if not user_id:
            raise HTTPException(status_code=401, detail="User not authenticated")
        result = db.execute(
            text(
                "SELECT id, user_message, llm_message, created_at FROM conversations WHERE user_id = :user_id ORDER BY created_at DESC LIMIT :limit"
            ),
            {"user_id": user_id, "limit": limit},
        )
        conversations = [
            dict(row._mapping) if hasattr(row, "_mapping") else dict(row)
            for row in result.fetchall()
        ]
        return {"user_id": user_id, "conversations": conversations, "count": len(conversations)}
    except Exception as e:
        logging.error(f"List user conversations error: {e}")
        raise HTTPException(status_code=500, detail=f"Error listing conversations: {str(e)}")

# --- Get Specific Conversation ---
@app.get("/user/conversations/{conversation_id}")
async def get_conversation_by_id(
    conversation_id: str,
    user_id: str = Depends(get_current_user_id),
    db: Session = Depends(get_db),
):
    """
    Retrieve a specific conversation by id.
    """
    try:
        result = db.execute(
            text(
                "SELECT id, user_message, llm_message, created_at FROM conversations WHERE id = :id AND user_id = :user_id"
            ),
            {"id": conversation_id, "user_id": user_id},
        )
        row = result.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="Conversation not found")
        conversation = dict(row._mapping) if hasattr(row, "_mapping") else dict(row)
        return conversation
    except Exception as e:
        logging.error(f"Get conversation by id error: {e}")
        raise HTTPException(status_code=500, detail=f"Error retrieving conversation: {str(e)}")

# --- Optionally: Semantic Search in Conversations ---
@app.get("/user/search-conversations/")
async def search_user_conversations(
    query: str,
    user_id: str = Depends(get_current_user_id),
    limit: int = 10,
):
    """
    Semantic search in user's conversations using Qdrant.
    """
    try:
        from app.qdrant_utils import search_documents
        results = search_documents(
            query,
            collection_name=CONV_COLLECTION,
            top_k=limit,
            filter={"user_id": user_id},
        )
        return {"query": query, "results": results, "count": len(results)}
    except Exception as e:
        logging.error(f"Search user conversations error: {e}")
        raise HTTPException(status_code=500, detail=f"Error searching conversations: {str(e)}")
@app.get("/health")
async def health_check():
    """Health check endpoint."""
    try:
        # Test database connection
        from app.db import engine
        with engine.connect() as connection:
            connection.execute(text("SELECT 1"))
        # Test Qdrant connection
        from app.qdrant_utils import client
        collections = client.get_collections()
        return {
            "status": "healthy",
            "database": "connected",
            "qdrant": "connected",
            "collections": len(collections.collections) if hasattr(collections, 'collections') else 0
        }
    except Exception as e:
        logging.error(f"Health check failed: {e}")
        return {
            "status": "unhealthy",
            "error": str(e)
        }
@app.get("/status")
async def get_status():
    """Get system status and statistics."""
    try:
        # Get product count
        products = get_all_products_from_supabase()
        product_count = len(products)
        # Get collection info
        try:
            from app.qdrant_utils import client
            collections_info = client.get_collections()
            collections = []
            for collection in collections_info.collections:
                try:
                    info = client.get_collection(collection.name)
                    collections.append({
                        "name": collection.name,
                        "vectors_count": info.vectors_count,
                        "status": info.status
                    })
                except Exception as e:
                    collections.append({
                        "name": collection.name,
                        "error": str(e)
                    })
        except Exception as e:
            collections = [{"error": f"Could not fetch collections: {e}"}]
        return {
            "system_status": "running",
            "products_count": product_count,
            "collections": collections,
            "endpoints": {
                "chat": "/chat",
                "egyptian_chat": "/egyptian-chat",
                "add_product": "/add-product/",
                "bulk_products": "/add-products-bulk/",
                "search_products": "/search-products/",
                "upload_document": "/upload-document/"
            }
        }
    except Exception as e:
        logging.error(f"Status check error: {e}")
        raise HTTPException(status_code=500, detail=f"Error getting status: {str(e)}")
# --- IMPROVED CHAT ENDPOINT
@app.post("/chat")
async def chat_endpoint(
    request: ChatRequest,
    fastapi_request: Request,
    user_id: str = Depends(get_current_user_id),
    db: Session = Depends(get_db),
):
    """
    Enhanced chat endpoint with improved multi-product search and better Arabic support.
    """
    try:
        question = request.question
        logging.info(f"Processing question: {question}")
        # Get conversation history
        conversation_history = []
        if user_id:
            conversation_history = get_conversation_history(user_id, limit=5)
        history_context = ""
        if conversation_history:
            history_context = "\n".join([
                f"Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {turn['user_message']}\nØ§Ù„Ù…Ø³Ø§Ø¹Ø¯: {turn['llm_response']}" 
                for turn in conversation_history
            ])
        # Use enhanced product search
        matched_products = await enhanced_product_search(question, top_k=8)
        # --- Ensure accurate product info by fetching from main DB and matching normalized Arabic ---
        all_products = get_all_products_from_supabase()
        products_by_id = {str(p.get("id")): p for p in all_products if p.get("id") is not None}
        # Supplement Qdrant results with normalized Arabic/Egyptian matching
        extra_matches = []
        for product in all_products:
            if query_matches_product(question, product):
                # Avoid duplicates
                if not any(str(product.get("id")) == str(mp.get("id")) for mp in matched_products):
                    extra_matches.append(product)
        matched_products += extra_matches
        # Merge Qdrant results with up-to-date DB info
        accurate_products = []
        for p in matched_products:
            pid = str(p.get("id"))
            if pid in products_by_id:
                accurate_products.append(products_by_id[pid])
            else:
                accurate_products.append(p)  # fallback if not found
        if accurate_products:
            product_context = ""
            for i, product_data in enumerate(accurate_products, 1):
                in_stock_ar = "Ù†Ø¹Ù… âœ…" if product_data.get('in_stock', False) else "Ù„Ø§ âŒ"
                quantity = product_data.get('quantity', 0)
                product_context += (
                    f"ğŸ”¹ Ø§Ù„Ù…Ù†ØªØ¬ {i}: {product_data.get('name', '')}\n"
                    f"ğŸ“¦ Ù…ØªÙˆÙØ± ÙÙŠ Ø§Ù„Ù…Ø®Ø²ÙˆÙ†: {in_stock_ar}\n"
                    f"ğŸ”¢ Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…ØªÙˆÙØ±Ø©: {quantity}\n"
                    f"ğŸŒ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø©: {product_data.get('image_url', '')}\n"
                )
                description = product_data.get('description', '')
                if description:
                    product_context += f"ğŸ“„ Ø§Ù„ÙˆØµÙ: {description}\n"
                category = product_data.get('category', '')
                if category:
                    product_context += f"ğŸ“‚ Ø§Ù„ØªØµÙ†ÙŠÙ: {category}\n"
                product_context += "\n"
            # Create comprehensive prompt
            prompt = f"""
Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:
{history_context}
Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©:
{product_context}
Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ„: {question}
ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
1. Ø§Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙˆØ¯ÙˆØ¯Ø© ÙˆÙ…ÙÙŠØ¯Ø©
2. Ø§Ø°ÙƒØ± ÙƒÙ„ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø¹ ØªÙØ§ØµÙŠÙ„Ù‡Ø§
3. ÙˆØ¶Ø­ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆÙØ± ÙˆØ§Ù„ÙƒÙ…ÙŠØ© Ù„ÙƒÙ„ Ù…Ù†ØªØ¬
4. Ø§Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù†ØªØ¬ ØºÙŠØ± Ù…ØªÙˆÙØ±ØŒ Ø§Ù‚ØªØ±Ø­ Ø¨Ø¯Ø§Ø¦Ù„ Ø¥Ù† ÙˆØ¬Ø¯Øª
5. Ø§Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø¹Ø¯Ø© Ù…Ù†ØªØ¬Ø§ØªØŒ Ø§Ø¬Ø¨ Ø¹Ù† ÙƒÙ„ Ù…Ù†ØªØ¬ Ø¨ÙˆØ¶ÙˆØ­
6. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ù„Ø¬Ø¹Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø£ÙƒØ«Ø± ÙˆØ¶ÙˆØ­Ø§Ù‹
"""
            response = call_deepseek(prompt)
            # Store conversation
            if user_id:
                store_conversation_with_embedding(user_id, question, response, db=db)
            return {"response": response}
        # Fallback to FAQ search if no products found
        logging.info("No products found, searching FAQ")
        faq_results = search_documents(question, collection_name="support_docs")
        faq_context = "\n".join([result["text"] for result in faq_results]) if faq_results else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªØ§Ø­Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©."
        prompt = f"""
Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:
{history_context}
Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©:
{faq_context}
Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ„: {question}
Ø§Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©ØŒ Ø§Ù†ØµØ­ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¨Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ ÙØ±ÙŠÙ‚ Ø§Ù„Ø¯Ø¹Ù….
"""
        response = call_deepseek(prompt)
        if user_id:
            store_conversation_with_embedding(user_id, question, response, db=db)
        return {"response": response}
    except Exception as e:
        logging.error(f"Chat endpoint error: {e}")
        return {"response": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø£Ùˆ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ ÙØ±ÙŠÙ‚ Ø§Ù„Ø¯Ø¹Ù…."}
# IMPROVED EGYPTIAN CHAT ENDPOINT
@app.post("/egyptian-chat")
async def egyptian_chat_endpoint(
    request: ChatRequest,
    fastapi_request: Request,
    user_id: str = Depends(get_current_user_id),
    db: Session = Depends(get_db),
):
    """
    Egyptian Arabic chat with enhanced product search.
    """
    try:
        question = request.question
        logging.info(f"Processing Egyptian chat question: {question}")
        # Get conversation history
        conversation_history = []
        if user_id:
            conversation_history = get_conversation_history(user_id, limit=5)
        history_context = ""
        if conversation_history:
            history_context = "\n".join([
                f"Ø§Ù„Ø¹Ù…ÙŠÙ„: {turn['user_message']}\nØ§Ù„Ù…Ø³Ø§Ø¹Ø¯: {turn['llm_response']}" 
                for turn in conversation_history
            ])
        # Enhanced product search
        matched_products = await enhanced_product_search(question, top_k=8)
        if matched_products:
            logging.info(f"Found {len(matched_products)} products for Egyptian chat")
            product_context = ""
            for i, product_data in enumerate(matched_products, 1):
                in_stock_eg = "Ø£ÙŠÙˆÙ‡ Ù…ÙˆØ¬ÙˆØ¯ âœ…" if product_data.get('in_stock', False) else "Ù„Ø£ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ âŒ"
                quantity = product_data.get('quantity', 0)
                product_context += (
                    f"ğŸ”¹ Ø§Ù„Ù…Ù†ØªØ¬ {i}: {product_data.get('name', '')}\n"
                    f"ğŸ“¦ Ù…ØªÙˆÙØ±: {in_stock_eg}\n"
                    f"ğŸ”¢ Ø§Ù„ÙƒÙ…ÙŠØ©: {quantity}\n"
                    f"ğŸŒ Ù„ÙŠÙ†Ùƒ Ø§Ù„ØµÙˆØ±Ø©: {product_data.get('image_url', '')}\n"
                )
                description = product_data.get('description', '')
                if description:
                    product_context += f"ğŸ“„ Ø§Ù„ÙˆØµÙ: {description}\n"
                category = product_data.get('category', '')
                if category:
                    product_context += f"ğŸ“‚ Ø§Ù„Ù†ÙˆØ¹: {category}\n"
                product_context += "\n"
            prompt = f"""
Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù„ÙŠ ÙØ§Øª:
{history_context}
Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª:
{product_context}
Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ„: {question}
ØªØ¹Ù„ÙŠÙ…Ø§Øª:
1. Ø¬Ø§ÙˆØ¨ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…ÙŠØ©
2. ÙƒÙˆÙ† ÙˆØ¯ÙˆØ¯ ÙˆØ¨Ø³ÙŠØ· ÙÙŠ Ø§Ù„ÙƒÙ„Ø§Ù…
3. Ø§Ø°ÙƒØ± ÙƒÙ„ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù„ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø³Ø£Ù„ Ø¹Ù†Ù‡Ø§
4. ÙˆØ¶Ø­ Ø¥ÙŠÙ‡ Ø§Ù„Ù…ØªÙˆÙØ± ÙˆØ¥ÙŠÙ‡ Ù…Ø´ Ù…ØªÙˆÙØ±
5. Ù„Ùˆ Ø­Ø§Ø¬Ø© Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ø§Ù‚ØªØ±Ø­ Ø¨Ø¯Ø§ÙŠÙ„
6. Ø§Ø³ØªØ®Ø¯Ù… ÙƒÙ„Ù…Ø§Øª Ø²ÙŠ "Ø£ÙŠÙˆÙ‡"ØŒ "Ù„Ø£"ØŒ "ÙƒØ¯Ù‡"ØŒ "ÙŠØ¹Ù†ÙŠ"
7. Ø®Ù„ÙŠ Ø§Ù„Ø±Ø¯ Ù…ÙÙŠØ¯ ÙˆÙ…ÙÙ‡ÙˆÙ…
"""
            response = call_deepseek(prompt)
            if user_id:
                store_conversation_with_embedding(user_id, question, response, db=db)
            return {"response": response}
        # FAQ fallback
        faq_results = search_documents(question, collection_name="support_docs")
        faq_context = "\n".join([result["text"] for result in faq_results]) if faq_results else "Ù…ÙÙŠØ´ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªØ§Ø­Ø©."
        prompt = f"""
Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù„ÙŠ ÙØ§Øª:
{history_context}
Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
{faq_context}
Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ„: {question}
Ø¬Ø§ÙˆØ¨ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ©. Ù„Ùˆ Ù…Ø´ Ù„Ø§Ù‚ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒÙØ§ÙŠØ©ØŒ Ù‚ÙˆÙ„ Ù„Ù„Ø¹Ù…ÙŠÙ„ ÙŠØªØµÙ„ Ø¨Ø§Ù„Ø¯Ø¹Ù….
"""
        response = call_deepseek(prompt)
        if user_id:
            store_conversation_with_embedding(user_id, question, response, db=db)
        return {"response": response}
    except Exception as e:
        logging.error(f"Egyptian chat error: {e}")
        return {"response": "Ø¹Ø°Ø±Ø§Ù‹ ÙŠØ§ ÙÙ†Ø¯Ù…ØŒ Ø­ØµÙ„ Ø®Ø·Ø£. Ù…Ù…ÙƒÙ† ØªØ¬Ø±Ø¨ ØªØ§Ù†ÙŠ Ø£Ùˆ ØªØªØµÙ„ Ø¨Ø§Ù„Ø¯Ø¹Ù…ØŸ"}